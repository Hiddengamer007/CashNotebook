{
  "metadata": {
    "kernelspec": {
      "name": "",
      "display_name": ""
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9708650e-604b-46d8-82f5-10a627e52825",
      "cell_type": "markdown",
      "source": "## Ich steh auf Femboys",
      "metadata": {}
    },
    {
      "id": "7e06b112-a256-452d-8ae0-708dd6dcae6e",
      "cell_type": "code",
      "source": "# applio_installer_and_launcher.py\n# Paste this into a notebook cell and run.\n# It runs the official Applio installer and then launches Applio,\n# streaming stdout/stderr back to the notebook in real time.\n\nimport os\nimport sys\nimport subprocess\nimport threading\nimport time\nfrom pathlib import Path\n\nREPO_URL = \"https://github.com/IAHispano/Applio.git\"\nREPO_DIR = \"Applio\"\nRUN_INSTALL = True   # set False if you already ran the install and just want to launch\nSKIP_APPLIO_LAUNCH = False  # set True to stop after install\n\ndef stream_process(cmd, cwd=None, env=None):\n    \"\"\"\n    Run a command (list) and stream combined stdout/stderr line-by-line.\n    Returns the process's returncode.\n    \"\"\"\n    print(f\"\\n>>> RUNNING: {' '.join(cmd)}  (cwd={cwd})\\n\")\n    # Ensure binary mode text streaming\n    p = subprocess.Popen(cmd, cwd=cwd, env=env,\n                         stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n                         bufsize=1, text=True, universal_newlines=True)\n\n    try:\n        for line in p.stdout:\n            # flush each line to the output cell immediately\n            print(line.rstrip())\n    except Exception as e:\n        print(f\"[streaming error] {e}\")\n    finally:\n        p.wait()\n        rc = p.returncode\n        print(f\"\\n<<< PROCESS EXIT CODE: {rc}\\n\")\n        return rc\n\ndef ensure_git_clone():\n    if Path(REPO_DIR).exists():\n        print(f\"Repo folder '{REPO_DIR}' already exists; skipping clone.\")\n        return 0\n    cmd = [\"git\", \"clone\", REPO_URL, REPO_DIR]\n    return stream_process(cmd)\n\ndef run_repo_install():\n    # prefer running the repo's provided install script so it sets up venv / ffmpeg / requirements\n    installer_sh = Path(REPO_DIR) / \"run-install.sh\"\n    if not installer_sh.exists():\n        print(\"Installer script 'run-install.sh' not found in repo; aborting install step.\")\n        return 1\n\n    # Make sure the script is executable; use bash to run it\n    cmd = [\"bash\", str(installer_sh)]\n    return stream_process(cmd, cwd=REPO_DIR)\n\ndef detect_torch_gpu(venv_python=None):\n    \"\"\"\n    Run a small Python snippet in the venv (or current python) to detect torch + GPU/hip info.\n    Returns tuple (ok:boolean, output_str).\n    \"\"\"\n    py = venv_python or sys.executable\n    check = (\n        \"import sys, json\\n\"\n        \"info = {'python': sys.executable}\\n\"\n        \"try:\\n\"\n        \"  import torch\\n\"\n        \"  info['torch_version'] = getattr(torch,'__version__',None)\\n\"\n        \"  info['cuda_available'] = torch.cuda.is_available() if hasattr(torch,'cuda') else False\\n\"\n        \"  info['has_hip'] = hasattr(torch.version,'hip') and torch.version.hip is not None\\n\"\n        \"except Exception as e:\\n\"\n        \"  info['torch_error'] = str(e)\\n\"\n        \"print(json.dumps(info))\\n\"\n    )\n    cmd = [py, \"-c\", check]\n    try:\n        out = subprocess.check_output(cmd, text=True, stderr=subprocess.STDOUT)\n        return True, out.strip()\n    except subprocess.CalledProcessError as e:\n        return False, (e.output or str(e))\n\ndef run_applio():\n    launcher = Path(REPO_DIR) / \"run-applio.sh\"\n    if not launcher.exists():\n        # fallback: some setups may prefer `python app.py`\n        fallback = Path(REPO_DIR) / \"app.py\"\n        if fallback.exists():\n            print(\"run-applio.sh missing; falling back to 'python app.py'\")\n            return stream_process([sys.executable, str(fallback)], cwd=REPO_DIR)\n        else:\n            print(\"No run-applio.sh or app.py found to launch Applio.\")\n            return 1\n    return stream_process([\"bash\", str(launcher)], cwd=REPO_DIR)\n\ndef main():\n    print(\"Starting Applio installer+launcher helper...\\n\")\n    # 1) clone repo if needed\n    rc = ensure_git_clone()\n    if rc != 0:\n        print(\"git clone failed. If the environment blocks git, please upload the repository into the notebook filesystem.\")\n        # proceed anyway in case repo already present / partial\n    # 2) run repo installer (streams output)\n    if RUN_INSTALL:\n        rc = run_repo_install()\n        if rc != 0:\n            print(\"Installer exited with non-zero code. Continue at your own risk.\")\n    else:\n        print(\"RUN_INSTALL is False; skipping installer step as requested.\")\n\n    # 3) detect torch / GPU in the venv if present\n    venv_py = None\n    venv_path = Path(REPO_DIR) / \".venv\" / \"bin\" / \"python\"\n    if venv_path.exists():\n        venv_py = str(venv_path)\n        ok, out = detect_torch_gpu(venv_python=venv_py)\n    else:\n        # fall back to current python\n        ok, out = detect_torch_gpu()\n    print(\"\\n=== PyTorch / GPU probe ===\")\n    if ok:\n        print(out)\n        if \"'cuda_available': true\" in out.lower() or '\"cuda_available\": true' in out:\n            print(\"\\nGood news: CUDA-enabled PyTorch detected. That usually means NVIDIA GPU support.\")\n        else:\n            print(\"\\nNo CUDA available (or PyTorch not GPU-enabled). If you have an AMD GPU and want training, you typically need a ROCm-built PyTorch / special wheels. See the notes in your notebook.\")\n    else:\n        print(\"Could not run torch probe. Output below:\")\n        print(out)\n\n    if SKIP_APPLIO_LAUNCH:\n        print(\"SKIP_APPLIO_LAUNCH is True; exiting now.\")\n        return\n\n    # 4) launch Applio (streams live)\n    rc = run_applio()\n    if rc != 0:\n        print(\"Applio launcher exited with non-zero code. Check the logs above for errors.\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "14a36095-95d7-4d78-a697-eb04d6568bcb",
      "cell_type": "markdown",
      "source": "# Manual Executions:",
      "metadata": {}
    },
    {
      "id": "d45cec0b-d198-43c0-8058-72662d5297df",
      "cell_type": "code",
      "source": "import subprocess\nimport threading\nimport sys\nimport os\nimport shlex\n\ndef stream_process(command):\n    \"\"\"\n    Runs a shell command and streams stdout/stderr live.\n    Blocks until process finishes.\n    \"\"\"\n    print(f\"\\n>>> Running: {command}\\n\")\n\n    # Start subprocess\n    process = subprocess.Popen(\n        command,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        bufsize=1\n    )\n\n    # Stream output live\n    try:\n        for line in process.stdout:\n            print(line.rstrip())\n    except Exception as e:\n        print(f\"[Streaming error]: {e}\")\n\n    process.wait()\n    print(f\"\\n<<< Exit code: {process.returncode}\\n\")\n    return process.returncode\n\n\ndef interactive_loop():\n    print(\"Interactive Subprocess Shell\")\n    print(\"Type commands to execute.\")\n    print(\"Type 'exit' or 'quit' to stop.\\n\")\n\n    while True:\n        try:\n            command = input(\"cmd> \").strip()\n        except (EOFError, KeyboardInterrupt):\n            print(\"\\nExiting.\")\n            break\n\n        if not command:\n            continue\n\n        if command.lower() in [\"exit\", \"quit\"]:\n            print(\"Goodbye.\")\n            break\n\n        stream_process(command)\n\n\nif __name__ == \"__main__\":\n    interactive_loop()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}